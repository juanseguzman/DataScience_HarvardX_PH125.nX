---
title: 'Data Science: Linear Regression - HarvardX: PH125.7x'
author: 'Luiz Cunha'
date: '2019-08-14'
output: html_notebook
---

# Section 3: Confounding

## Overview

In the **Confounding** section, you will learn what is perhaps the most important lesson of statistics: that correlation is not causation.

After completing this section, you will be able to:

* Identify examples of **spurious correlation** and explain how **data dredging** can lead to spurious correlation.
* Explain how **outliers** can drive correlation and learn to adjust for outliers using Spearman correlation.
* Explain how **reversing cause and effect** can lead to associations being confused with causation.
Understand how **confounders** can lead to the misinterpretation of associations.
Explain and give examples of **Simpson's Paradox**.

This section has one part: **Correlation is Not Causation**.

```{r}
options(digits = 3)
library(tidyverse)
library(broom)
```


## 3.1 Correlation is not Causation

### 3.1.1 Correlation is Not Causation: Spurious Correlation

**Key points**

* Association/correlation is not causation.
* p-hacking is a topic of much discussion because it is a problem in scientific publications. Because publishers tend to reward statistically significant results over negative results, there is an incentive to report significant results.

**Code**
```{r}
# generate the Monte Carlo simulation
N <- 25
g <- 1000000
sim_data <- tibble(group = rep(1:g, each = N), x = rnorm(N * g), y = rnorm(N * g))

# calculate correlation between X,Y for each group
res <- sim_data %>% 
  group_by(group) %>% 
  summarize(r = cor(x, y)) %>% 
  arrange(desc(r))
res

# plot points from the group with maximum correlation
sim_data %>% filter(group == res$group[which.max(res$r)]) %>%
  ggplot(aes(x, y)) +
  geom_point() + 
  geom_smooth(method = "lm")

# histogram of correlation in Monte Carlo simulations
res %>% ggplot(aes(x=r)) + geom_histogram(binwidth = 0.1, color = "black")

# linear regression on group with maximum correlation
library(broom)
sim_data %>% 
  filter(group == res$group[which.max(res$r)]) %>%
  do(tidy(lm(y ~ x, data = .)))
```


### 3.1.2 Correlation is Not Causation: Outliers

**Key points**

* Correlations can be caused by **outliers**.
* The **Spearman correlation** is calculated based on the ranks of data.

**Code**
```{r}
# simulate independent X, Y and standardize all except entry 23
set.seed(1985)
x <- rnorm(100,100,1)
y <- rnorm(100,84,1)
x[-23] <- scale(x[-23])
y[-23] <- scale(y[-23])

# plot shows the outlier
qplot(x, y, alpha = 0.5)

# outlier makes it appear there is correlation
cor(x,y)
cor(x[-23], y[-23])

# use rank instead
qplot(rank(x), rank(y))
cor(rank(x), rank(y))

# Spearman correlation with cor function
cor(x, y, method = "spearman")
```


### 3.1.3 Correlation is Not Causation: Reversing Cause and Effect

**Key points**

* Another way association can be confused with causation is when the cause and effect are reversed.
* As discussed in the video, in the Galton data, when father and son were reversed in the regression, the model was technically correct. The estimates and p-values were obtained correctly as well. What was incorrect was the interpretation of the model.

*Code**
```{r}
# cause and effect reversal using son heights to predict father heights
library(HistData)
data("GaltonFamilies")
GaltonFamilies %>%
  filter(childNum == 1 & gender == "male") %>%
  select(father, childHeight) %>%
  rename(son = childHeight) %>% 
  do(tidy(lm(father ~ son, data = .)))
```

### 3.1.4 Correlation is not Causation: Confounders

**Key points**

* If X and Y are correlated, we call Z a **confounder** if changes in Z causes changes in both X and Y.

**Code**
```{r}
# UC-Berkeley admission data
library(dslabs)
data(admissions)
admissions

# percent men and women accepted
admissions %>% group_by(gender) %>% 
  summarize(percentage = 
              round(sum(admitted*applicants)/sum(applicants),1))

# test whether gender and admission are independent
admissions %>% group_by(gender) %>% 
  summarize(total_admitted = round(sum(admitted / 100 * applicants)), 
            not_admitted = sum(applicants) - sum(total_admitted)) %>%
  select(-gender) %>% 
  do(tidy(chisq.test(.)))

# percent admissions by major
admissions %>% select(major, gender, admitted) %>%
  spread(gender, admitted) %>%
  mutate(women_minus_men = women - men)

# plot total percent admitted to major versus percent women applicants
admissions %>% 
  group_by(major) %>% 
  summarize(major_selectivity = sum(admitted * applicants) / sum(applicants),
            percent_women_applicants = sum(applicants * (gender=="women")) /
                                             sum(applicants) * 100) %>%
  ggplot(aes(major_selectivity, percent_women_applicants, label = major)) +
  geom_text()

# plot number of applicants admitted and not
admissions %>%
  mutate(yes = round(admitted/100*applicants), no = applicants - yes) %>%
  select(-applicants, -admitted) %>%
  gather(admission, number_of_students, -c("major", "gender")) %>%
  ggplot(aes(gender, number_of_students, fill = admission)) +
  geom_bar(stat = "identity", position = "stack") +
  facet_wrap(. ~ major)

admissions %>% 
  mutate(percent_admitted = admitted * applicants/sum(applicants)) %>%
  ggplot(aes(gender, y = percent_admitted, fill = major)) +
  geom_bar(stat = "identity", position = "stack")

# condition on major and then look at differences
admissions %>% ggplot(aes(major, admitted, col = gender, size = applicants)) + geom_point()

# average difference by major
admissions %>%  group_by(gender) %>% summarize(average = mean(admitted))
```

### 3.1.5 Simpson's Paradox

**Key points**

* **Simpson's Paradox** happens when we see the sign of the correlation flip when comparing the entire dataset with specific strata. 


### 3.1.6 Assessment: Correlation is Not Causation
...


## 3.2 Assessment: Confounding (Verified Learners only)

For this set of exercises, we examine the data from a 2014 PNAS paper that analyzed success rates from funding agencies in the Netherlands and concluded:

> "our results reveal gender bias favoring male applicants over female applicants in the prioritization of their "quality of researcher" (but not "quality of proposal") evaluations and success rates, as well as in the language used in instructional and evaluation materials."

A response was published a few months later titled No evidence that gender contributes to personal research funding success in The Netherlands: A reaction to Van der Lee and Ellemers, which concluded:

> "However, the overall gender effect borders on statistical significance, despite the large sample. Moreover, their conclusion could be a prime example of Simpson's paradox; if a higher percentage of women apply for grants in more competitive scientific disciplines (i.e., with low application success rates for both men and women), then an analysis across all disciplines could incorrectly "show evidence" of gender inequality." 

Who is right here: the original paper or the response? Here, you will examine the data and come to your own conclusion.

The main evidence for the conclusion of the original paper comes down to a comparison of the percentages. The information we need was originally in Table S1 in the paper, which we include in **dslabs**:

```{r}
library(dslabs)
data("research_funding_rates")
research_funding_rates
```


#### Question 1
Construct a two-by-two table of gender (men/women) by award status (awarded/not) using the total numbers across all disciplines.

Q: What is the number of men not awarded?  
Q: What is the number of women not awarded?
```{r}
two_by_two <- research_funding_rates %>% 
    select(-discipline) %>% 
    summarize_all(list(sum)) %>%
    summarize(yes_men = awards_men, 
              no_men = applications_men - awards_men, 
              yes_women = awards_women, 
              no_women = applications_women - awards_women) %>%
    gather %>%
    separate(key, c("awarded", "gender")) %>%
    spread(gender, value)
two_by_two
```


#### Question 2
Use the two-by-two table from Question 1 to compute the percentages of men awarded versus women awarded.

Q: What is the percentage of men awarded?  
Q: What is the percentage of women awarded?
```{r}
two_by_two %>% 
    mutate(men = round(men/sum(men)*100, 1), women = round(women/sum(women)*100, 1)) %>%
    filter(awarded == "yes")
```

#### Question 3
Run a **chi-squared test** on the two-by-two table to determine whether the difference in the two success rates is significant. (You can use tidy to turn the output of *chisq.test* into a data frame as well.)

What is the p-value of the difference in funding rate?
```{r}
two_by_two %>% select(-awarded) %>% chisq.test() %>% tidy()
```

####Question 4
There may be an association between gender and funding. But can we infer causation here? Is gender bias causing this observed difference? The response to the original paper claims that what we see here is similar to the UC Berkeley admissions example. Specifically they state that this "could be a prime example of Simpson's paradox; if a higher percentage of women apply for grants in more competitive scientific disciplines, then an analysis across all disciplines could incorrectly show 'evidence' of gender inequality."

To settle this dispute, use this dataset with number of applications, awards, and success rate for each gender:
```{r}
dat <- research_funding_rates %>% 
      mutate(discipline = reorder(discipline, success_rates_total)) %>%
      rename(success_total = success_rates_total,
             success_men = success_rates_men,
             success_women = success_rates_women) %>%
      gather(key, value, -discipline) %>%
      separate(key, c("type", "gender")) %>%
      spread(type, value) %>%
      filter(gender != "total")
dat
```

To check if this is a case of Simpson's paradox, plot the success rates versus disciplines, which have been ordered by overall success, with colors to denote the genders and size to denote the number of applications.
```{r}
dat %>% 
    ggplot(aes(x = discipline, y = success, size = applications, col = gender)) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    geom_point()
```

In which fields do men have a higher success rate than women?
Select ALL that apply.